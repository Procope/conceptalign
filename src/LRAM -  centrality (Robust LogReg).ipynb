{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment and centrality\n",
    "\n",
    "#### In this notebook, we estimate alignment in conversations and quantify to which amount alignment  is influenced by the centrality of the interlocutors.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm \n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import utils\n",
    "from talkpages import WikiCorpusReader, WikiCorpus\n",
    "from alignment import Alignment\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The conversations are taken from a selection of 10 topics from the Controversial TalkPages corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = ['religion',\n",
    "          'science', \n",
    "          'politics', \n",
    "          'history', \n",
    "          'people',\n",
    "          'philosophy', \n",
    "          'sports',\n",
    "          'linguistics', \n",
    "          'psychiatry',\n",
    "          'environment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To count alignment, we use a selection of marker categories and tokens from the LIWC dictionaries. There is no overlap between any two categories due to some preprocessing (`marker selection.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_CATEGORIES = {'stylistic': [\n",
    "                        'articles',\n",
    "                        'negations',\n",
    "                        'prepositions',\n",
    "                        'numbers',\n",
    "                        'pronouns'\n",
    "                    ], \n",
    "                    'rhetoric': [\n",
    "                        'tentative',   \n",
    "                        'certainty',\n",
    "                        'discrepancy',\n",
    "                        'inclusive',\n",
    "                        'exclusive'\n",
    "                    ],\n",
    "                    'discursive': [\n",
    "                        'causation',\n",
    "                        'insight',\n",
    "                        'inhibition',\n",
    "                        'communication',\n",
    "                        'cognitive process',\n",
    "                        'sensory process',\n",
    "                        'motion'\n",
    "                    ],\n",
    "                    'stance': [\n",
    "                        'optimism',\n",
    "                        'anger',\n",
    "                        'anxiety',\n",
    "                        'sadness',\n",
    "                    ]}\n",
    "\n",
    "\n",
    "# Keep a list of category names for convenience.\n",
    "CATEGORY_LIST = []\n",
    "for cats in META_CATEGORIES.values():\n",
    "    CATEGORY_LIST.extend(cats)\n",
    "    \n",
    "# Load the filtered lists of markers. \n",
    "with open('../../data/liwc/final.dict', 'rb') as f:\n",
    "    MARKER_DICT = pickle.load(f)\n",
    "    \n",
    "    marker_list = []\n",
    "    for markers in MARKER_DICT.values():\n",
    "        marker_list.extend(markers)\n",
    "    MARKER_LIST = list(set(marker_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Last but not least, we need to choose a centrality measure: _eigenvector_ or _betweenness centrality_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTRALITY = 'eigenvector'\n",
    "# CENTRALITY = 'betweenness'\n",
    "\n",
    "MODE = 'category'\n",
    "# MODE = 'cnw'\n",
    "\n",
    "MAX_ITERS = 100000\n",
    "N_SAMPLES = 4000\n",
    "TRACE_SIZE = 1000\n",
    "\n",
    "CAUCHY_ALPHA = -2\n",
    "CAUCHY_BETA = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We focus on `category-not-word` alignment to exclude cases of lexical repetition ([Doyle & Frank 2016](http://www.aclweb.org/anthology/P16-1050), pp. 531-532)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion\n",
      "***************\n",
      "religion, articles\n",
      "********************\n",
      "baseline intercept                    -2.06\n",
      "alignment intercept                    0.47\n",
      "coefficient centr(A)                  -0.92\n",
      "coefficient centr(B)                  -0.92\n",
      "guessing coefficient_logodds__        -1.05\n",
      "C_base                             -3596.19\n",
      "C_align                          -494324.09\n",
      "Name: Log-probability of test_point, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 85,104: 100%|██████████| 100000/100000 [08:17<00:00, 201.11it/s]   \n",
      "Finished [100%]: Average Loss = 85,104\n",
      "INFO:pymc3.variational.inference:Finished [100%]: Average Loss = 85,104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 4000 ... Done.\n",
      "                          mean        sd  mc_error   hpd_2.5  hpd_97.5\n",
      "baseline intercept   -1.540213  0.002321  0.000074 -1.544901 -1.535927\n",
      "alignment intercept   0.105144  0.002264  0.000071  0.100988  0.109939\n",
      "coefficient centr(A) -0.020343  0.001859  0.000058 -0.023980 -0.016577\n",
      "coefficient centr(B) -0.003997  0.001983  0.000067 -0.008000 -0.000313\n",
      "guessing coefficient  0.412109  0.000710  0.000021  0.410679  0.413399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mario/GitHub/virtualenvs/align/lib/python3.7/site-packages/matplotlib/axes/_base.py:3604: MatplotlibDeprecationWarning: \n",
      "The `ymin` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `bottom` instead.\n",
      "  alternative='`bottom`', obj_type='argument')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion, negations\n",
      "********************\n",
      "baseline intercept                     -2.06\n",
      "alignment intercept                     0.47\n",
      "coefficient centr(A)                   -0.92\n",
      "coefficient centr(B)                   -0.92\n",
      "guessing coefficient_logodds__         -1.05\n",
      "C_base                           -4168890.04\n",
      "C_align                            -42492.48\n",
      "Name: Log-probability of test_point, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 11,924:  46%|████▌     | 45941/100000 [03:45<06:44, 133.70it/s]    "
     ]
    }
   ],
   "source": [
    "for TOPIC in TOPICS:\n",
    "    \n",
    "    print('{}\\n{}'.format(TOPIC, '*'*15))\n",
    "    \n",
    "    # Load category-not-word alignment counts (Doyle & Frank, 2016)\n",
    "    with open('./counts-{}/{}.dill'.format(MODE, TOPIC), 'rb') as f:\n",
    "        if CENTRALITY == 'eigenvector':\n",
    "            N_base_all, N_align_all, C_base_all, C_align_all, dyad2centrality, _, _, _ = dill.load(f)\n",
    "        elif CENTRALITY == 'betweenness':\n",
    "            N_base_all, N_align_all, C_base_all, C_align_all, _, dyad2centrality, _, _ = dill.load(f)\n",
    "    \n",
    "    # Statistical modelling\n",
    "    for c, category in enumerate(CATEGORY_LIST):\n",
    "        \n",
    "        print('{}, {}\\n{}'.format(TOPIC, category, '*'*20))\n",
    "        \n",
    "        # Data\n",
    "        N_base, N_align, C_base, C_align = [], [], [], []\n",
    "        A_centrality, B_centrality = [], []\n",
    "        \n",
    "        # collect the counts for this category of markers\n",
    "        for dyad in N_base_all:\n",
    "            \n",
    "            if C_base_all[dyad][c] > N_base_all[dyad][c]:\n",
    "                continue\n",
    "            if C_align_all[dyad][c] > N_align_all[dyad][c]:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                A_centr, B_centr = dyad2centrality[dyad]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            N_base.append(N_base_all[dyad][c])\n",
    "            C_base.append(C_base_all[dyad][c])\n",
    "            N_align.append(N_align_all[dyad][c])\n",
    "            C_align.append(C_align_all[dyad][c])\n",
    "            A_centrality.append(A_centr)\n",
    "            B_centrality.append(B_centr)\n",
    "            \n",
    "        if not any(N_base):\n",
    "            print('N_base: all zeros.')\n",
    "        if not any(N_align):\n",
    "            print('N_align: all zeros.')\n",
    "        if not any(C_align):\n",
    "            print('C_align: all zeros.')\n",
    "        if not any(C_base):\n",
    "            print('C_base: all zeros.')\n",
    "            \n",
    "        if not (any(N_base) or any(N_align) or any(C_align) or any(C_base)):\n",
    "            continue\n",
    "        \n",
    "        A_centrality =  utils.standardise(A_centrality)\n",
    "        B_centrality =  utils.standardise(B_centrality)\n",
    "        \n",
    "        # A simple logistic model.\n",
    "        with pm.Model() as model:\n",
    "            # Parameters\n",
    "            beta0 = pm.Cauchy('baseline intercept', alpha=CAUCHY_ALPHA, beta=CAUCHY_BETA)\n",
    "            alpha0 = pm.Normal('alignment intercept', mu=0, sd=0.25)\n",
    "            alpha1 = pm.Normal('coefficient centr(A)', mu=0, sd=1)\n",
    "            alpha2 = pm.Normal('coefficient centr(B)', mu=0, sd=1)\n",
    "            \n",
    "            # Include a guessing coefficient for robust logistic regression\n",
    "            # (cfr. J. Kruschke, 2014, 'Doing Bayesian data analysis', pp. 635-636)\n",
    "            guess = pm.Beta('guessing coefficient', alpha=1, beta=9)  \n",
    "            \n",
    "            # Transformed parameters\n",
    "            mu_base  = guess * 0.5 + (1-guess) * pm.math.invlogit(beta0)            \n",
    "            mu_align = guess * 0.5 + (1-guess) * pm.math.invlogit(beta0+alpha0 + alpha1*A_centrality + alpha2*B_centrality)\n",
    "            \n",
    "            # Model\n",
    "            base_count  = pm.Binomial('C_base' , p=mu_base , observed=C_base, n=N_base)\n",
    "            align_count = pm.Binomial('C_align', p=mu_align, observed=C_align, n=N_align)\n",
    "        \n",
    "\n",
    "        # Inference\n",
    "        with model:\n",
    "            print(model.check_test_point())\n",
    "    \n",
    "            approx = pm.fit(n=MAX_ITERS, method='advi',\n",
    "                            callbacks=[pm.callbacks.CheckParametersConvergence(diff='absolute')])\n",
    "\n",
    "            print('Sampling {} ...'.format(N_SAMPLES), end=' ')\n",
    "            full_trace = approx.sample(draws=N_SAMPLES)\n",
    "            print('Done.')\n",
    "            \n",
    "            trace = full_trace[-TRACE_SIZE:]\n",
    "            trace_df = pm.trace_to_dataframe(trace)\n",
    "            trace_df.to_csv('./traces/{}/{}/{}-{}.csv'.format(MODE, CENTRALITY, TOPIC, category))\n",
    "        \n",
    "            print(pm.summary(trace))\n",
    "\n",
    "            pm.traceplot(trace, varnames=['baseline intercept',\n",
    "                                          'alignment intercept', \n",
    "                                          'coefficient centr(A)',\n",
    "                                          'coefficient centr(B)',\n",
    "                                          'guessing coefficient'])\n",
    "            \n",
    "            plt.savefig('plots/traceplots/{}/{}/{}-{}.pdf'.format(MODE, CENTRALITY, TOPIC, category))\n",
    "\n",
    "\n",
    "            pm.plot_posterior(trace)\n",
    "            plt.savefig('plots/posteriors/{}/{}/{}-{}.pdf'.format(MODE, CENTRALITY, TOPIC, category))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for TOPIC in TOPICS:\n",
    "    \n",
    "    print('{}\\n{}'.format(TOPIC, '*'*15))\n",
    "    \n",
    "    # Load dataframes with precomputed marker counts\n",
    "    csv_filename = './with_counts/{}_fullcounts.csv'.format(TOPIC)\n",
    "    corpus = WikiCorpus(csv_filename)\n",
    "    \n",
    "    # Obtain dataframe of conversational turns\n",
    "    turns = corpus.reply_pairs()\n",
    "    \n",
    "    # Generate network of TalkPages users \n",
    "    # (bool) prune: prune to the largest connected component?\n",
    "    users = corpus.get_users()\n",
    "    net = corpus.social_network(prune=False)\n",
    "    \n",
    "    # Compute centrality for each user and include into the dataframe of reply pairs\n",
    "    corpus.assign_centrality(CENTRALITY)\n",
    "    \n",
    "    # Initialise alignment tracker\n",
    "    al = Alignment(corpus, MARKER_DICT)\n",
    "    \n",
    "    # Compute (or load) category-not-word alignment counts (Doyle & Frank, 2016)\n",
    "    try:\n",
    "        with open('./counts-cnw-{}/{}.pickle'.format(CENTRALITY, TOPIC), 'rb') as d:\n",
    "            N_base_all, N_align_all, C_base_all, C_align_all, dyad2centrality = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        N_base_all, N_align_all, C_base_all, C_align_all, dyad2centrality = al.counts(mode='category-not-word', \n",
    "                                                                                      centrality=CENTRALITY)\n",
    "        with open('./counts-cnw-{}/{}.pickle'.format(CENTRALITY, TOPIC), 'wb') as d:\n",
    "            pickle.dump((N_base_all, N_align_all, C_base_all, C_align_all, dyad2centrality), f)\n",
    "        \n",
    "    \n",
    "    # Statistical modelling\n",
    "    for c, category in enumerate(CATEGORY_LIST):\n",
    "        \n",
    "        print('{}, {}\\n{}'.format(TOPIC, category, '*'*30))\n",
    "        \n",
    "        # Data:\n",
    "        # collect the counts for this category of markers\n",
    "        N_base, N_align, C_base, C_align = [], [], [], []\n",
    "        A_centrality, B_centrality = [], []\n",
    "        for dyad in N_base_all:\n",
    "            N_base.append(N_base_all[dyad][c])\n",
    "            C_base.append(C_base_all[dyad][c])\n",
    "            N_align.append(N_align_all[dyad][c])\n",
    "            C_align.append(C_align_all[dyad][c])\n",
    "            \n",
    "            A_centr, B_centr = dyad2centrality[dyad]\n",
    "            A_centrality.append(A_centr)\n",
    "            B_centrality.append(B_centr)\n",
    "            \n",
    "        # Transformed data\n",
    "        N_base = utils.standardise(N_base)\n",
    "        C_base = utils.standardise(C_base)\n",
    "        N_align = utils.standardise(N_align)\n",
    "        C_align = utils.standardise(C_align)\n",
    "        \n",
    "        # A simple logistic model.\n",
    "        with pm.Model() as model:\n",
    "            # Parameters\n",
    "            beta0 = pm.Cauchy('baseline intercept', alpha=0, beta=2.5)\n",
    "            alpha0 = pm.Normal('alignment intercept', mu=0, sd=0.25)\n",
    "            alpha1 = pm.Normal('coefficient centr(A)', mu=0, sd=1)\n",
    "            alpha2 = pm.Normal('coefficient centr(B)', mu=0, sd=1)\n",
    "            \n",
    "            # Include a guessing coefficient for robust logistic regression\n",
    "            # (cfr. J. Kruschke, 2014, 'Doing Bayesian data analysis', pp. 635-636)\n",
    "            guess = pm.Beta(alpha=1, beta=9)  \n",
    "            \n",
    "            # Transformed parameters\n",
    "            mu_base  = guess * 0.5 + (1-guess) * pm.math.invlogit(beta0)            \n",
    "            mu_align = guess * 0.5 + (1-guess) * pm.math.invlogit(beta0+alpha0 + alpha1*A_centralities + alpha2*B_centralities)\n",
    "            \n",
    "            # Model\n",
    "            base_count  = pm.Binomial('C_base' , p=mu_base , observed=C_base, n=N_base)\n",
    "            align_count = pm.Binomial('C_align', p=mu_align, observed=C_align, n=N_align)\n",
    "        \n",
    "\n",
    "        # Inference\n",
    "        with individual_model:\n",
    "            start = pm.find_MAP()\n",
    "            step = pm.NUTS(scaling=start)\n",
    "            \n",
    "            out_db = pm.backends.Text('./traces-{}/{}-{}'.format(CENTRALITY, TOPIC, category))\n",
    "            \n",
    "            trace = pm.sample(draws=2000, \n",
    "                              random_seed=13,\n",
    "                              progressbar=True,\n",
    "                              tune=500,\n",
    "                              chains=4,\n",
    "                              trace=out_db)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
